{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rszgAiTgUOEd"
   },
   "source": [
    "## This is BERT based fine tune model for binary prediction\n",
    "\n",
    "Loss function is customized. The custom loss functions requires 7 field including the target toxic indication. This means our model need to return 7 fields prediction to be able to use this loss function. Considering there is no existing model that returns 7 labels, I will need to use pretrained BERT model and add a Linear layer with 7 output fields (BertClass)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IbxV0iGAUqRc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('data'):\n",
    "  !mkdir data\n",
    "  # Download the training and the test corpus\n",
    "  !wget -nv --show-progress -O data/test.csv.zip https://www.dropbox.com/s/xp6bo8yo1vbv5yg/test.csv.zip?dl=1\n",
    "  !wget -nv --show-progress -O data/train.csv.zip https://www.dropbox.com/s/xei6z41mfrcnxcd/train.csv.zip?dl=1\n",
    "  # Download the pretrained weights for bert base. \n",
    "  !wget -nv --show-progress -O data/uncased_L-12_H-768_A-12.zip \\\n",
    "          https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "\n",
    "  !wget -nv --show-progress  -O data/cased_L-12_H-768_A-12.zip \\\n",
    "          https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip\n",
    "  # unzip weights & conifg and remove the original zip\n",
    "  !unzip -d data/ data/cased_L-12_H-768_A-12.zip && rm data/cased_L-12_H-768_A-12.zip\n",
    "  !unzip -d data/ data/uncased_L-12_H-768_A-12.zip && rm data/uncased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "0BWuHJtbUOEe",
    "outputId": "361aa221-eafb-47a1-f54e-b0c3084e84ae"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm, notebook\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "import pickle\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6iFu29LkUOEg"
   },
   "outputs": [],
   "source": [
    "# Let's activate CUDA for GPU based operations\n",
    "device=torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ij0-U4-lUOEj"
   },
   "outputs": [],
   "source": [
    "# In bert we need all inputs to have the same length, we will use the first 220 characters. \n",
    "MAX_SEQUENCE_LENGTH = 220\n",
    "SEED = 1234\n",
    "# We shall run a single epoch (ie. one pass over the data)\n",
    "EPOCHS = 1\n",
    "PATH = '.'#'/root/v2/week06/hw' # /root/v2/week06/hw\"\n",
    "DATA_DIR = os.path.join(PATH, \"data\")\n",
    "WORK_DIR = os.path.join(PATH, \"workingdir\")\n",
    "\n",
    "# Validation and training sizes are here. \n",
    "train_size= 1000000 # 1000000 \n",
    "valid_size= 500000  # 500000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbtwu2ocUOEm"
   },
   "source": [
    "This should be the files you downloaded earlier when you ran `download.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "jedPJmFgVVa1",
    "outputId": "38efca4f-5ed7-451f-aa62-680180df86a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (3.2.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (2020.7.14)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: sacremoses in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (4.42.1)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc2 in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (0.8.1rc2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sacremoses->transformers) (1.14.0)\n",
      "Requirement already satisfied: click in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from packaging->transformers) (2.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bNsHYCR5UOEp"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from transformers import BertModel, BertConfig,BertTokenizer, AdamW, get_linear_schedule_with_warmup,BertForSequenceClassification\n",
    "import transformers\n",
    "import random\n",
    "#from transformers import AdamW as BertAdam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHde7udAUOEt"
   },
   "source": [
    "We shall now load the model. When you run this, comment out the `capture` command to understand the archecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "s6i06ATuUOEt"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "bert_config = BertConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_1G4YHcUOEv"
   },
   "source": [
    "Bert needs a special formatting of sentences, so we have a sentence start and end token, as well as separators.   \n",
    "Thanks to this [script](https://www.kaggle.com/httpwwwfszyc/bert-in-keras-taming) for a fast convertor of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DrBmqp7BUOEv"
   },
   "outputs": [],
   "source": [
    "def convert_lines(example, max_seq_length,tokenizer):\n",
    "    max_seq_length -=2\n",
    "    all_tokens = []\n",
    "    longer = 0\n",
    "    for text in notebook.tqdm(example):\n",
    "        tokens_a = tokenizer.tokenize(text)\n",
    "        if len(tokens_a)>max_seq_length:\n",
    "            tokens_a = tokens_a[:max_seq_length]\n",
    "            longer += 1\n",
    "        one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"]+tokens_a+[\"[SEP]\"])+[0] * (max_seq_length - len(tokens_a))\n",
    "        all_tokens.append(one_token)\n",
    "    print(longer)\n",
    "    return np.array(all_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_qEXfL7UOEx"
   },
   "source": [
    "Now we load the BERT tokenizer and convert the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183,
     "referenced_widgets": [
      "e14b642ce67d4583b118cf9fcb852224",
      "1e03aed417bf419997f8085fd2810fd0",
      "b81cf91d91fc43af86793433688d2109",
      "87c3651ba1eb422fb6c08c10eeadcd0f",
      "e34be474391a44cc918e4b6aee0f938a",
      "3352e65d4cb643c592ea7772ee054dc6",
      "08df668ae923461e8ae9dfd14a07c11a",
      "d515018550e641c4b49f35d7f6ae5c80"
     ]
    },
    "id": "R9DizVjNUOEy",
    "outputId": "d1990425-2519-4190-b22e-3ffedd175076"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 1500000 records\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad706dc4d9b4eaaab9065640c5acf51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1500000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "33722\n",
      "CPU times: user 28min 5s, sys: 6.35 s, total: 28min 11s\n",
      "Wall time: 28min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, cache_dir=None,do_lower_case=True)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_all = pd.read_csv(os.path.join(DATA_DIR, \"train.csv.zip\")).sample(train_size+valid_size,random_state=SEED)\n",
    "print('loaded %d records' % len(train_all))\n",
    "\n",
    "# Make sure all comment_text values are strings\n",
    "train_all['comment_text'] = train_all['comment_text'].astype(str) \n",
    "\n",
    "sequences = convert_lines(train_all[\"comment_text\"].fillna(\"DUMMY_VALUE\"),MAX_SEQUENCE_LENGTH,tokenizer)\n",
    "train_all=train_all.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NJTdc6CsUOE9"
   },
   "outputs": [],
   "source": [
    "train_all['target']=(train_all['target']>=0.5).astype(float)\n",
    "# Training data - sentences\n",
    "X = sequences[:train_size] \n",
    "# Target - the toxicity. \n",
    "y = train_all[['target']].values[:train_size]\n",
    "X_val = sequences[train_size:]                \n",
    "y_val = train_all[['target']].values[train_size:]\n",
    "\n",
    "# Training data creations\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.tensor(X,dtype=torch.long), torch.tensor(y,dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Xvs2jTHuUOFH"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "9bRHW1KbuyoL"
   },
   "outputs": [],
   "source": [
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "\n",
    "# Overall\n",
    "weights = np.ones((len(X),)) / 4\n",
    "\n",
    "X_train = train_all[:train_size]\n",
    "\n",
    "# Subgroup\n",
    "weights += (X_train[identity_columns].fillna(0).values>=0.5).sum(axis=1).astype(bool).astype(np.int) / 4\n",
    "\n",
    "# Background Positive, Subgroup Negative\n",
    "weights += (( (X_train['target'].values>=0.5).astype(bool).astype(np.int) +\n",
    "   (X_train[identity_columns].fillna(0).values<0.5).sum(axis=1).astype(bool).astype(np.int) ) > 1 ).astype(bool).astype(np.int) / 4\n",
    "\n",
    "# Background Negative, Subgroup Positive\n",
    "weights += (( (X_train['target'].values<0.5).astype(bool).astype(np.int) +\n",
    "   (X_train[identity_columns].fillna(0).values>=0.5).sum(axis=1).astype(bool).astype(np.int) ) > 1 ).astype(bool).astype(np.int) / 4\n",
    "loss_weight = 1.0 / weights.mean()\n",
    "\n",
    "y_train = np.vstack([(X_train['target'].values>=0.5).astype(np.int),weights]).T\n",
    "y_aux_train = X_train[['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']]\n",
    "y_train_torch = torch.tensor(np.hstack([y_train, y_aux_train]), dtype=torch.float32)\n",
    "\n",
    "#prepar validation data\n",
    "X_val_all = train_all[train_size:]\n",
    "y_val = (X_val_all['target'].values>=0.5).astype(np.int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lMIM4ZZRUOFT"
   },
   "outputs": [],
   "source": [
    "def custom_loss(data, targets):\n",
    "    ''' Define custom loss function for weighted BCE on 'target' column '''\n",
    "    bce_loss_1 = nn.BCEWithLogitsLoss(weight=targets[:,1:2])(data[:,:1],targets[:,:1])\n",
    "    bce_loss_2 = nn.BCEWithLogitsLoss()(data[:,1:],targets[:,2:])\n",
    "    return (bce_loss_1 * loss_weight) + bce_loss_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a BERT fine tuning model that generate 7 output numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pTHzGJJ_C6xj"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Creating the customized model, by adding a drop out and a dense layer on top of bert to get the final output for the model. \n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.bertlayer = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(self.bertlayer.config.hidden_dropout_prob)\n",
    "        self.linearlayer = nn.Linear(self.bertlayer.config.hidden_size, 7, bias = False) \n",
    "        self.output = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, ids, attention_mask, token_type_ids = None):\n",
    "        output_1= self.bertlayer(ids, attention_mask, token_type_ids)\n",
    "        dropout = self.dropout(output_1[1])\n",
    "        output_2 = self.linearlayer(dropout)\n",
    "        #output = self.output(output_2)\n",
    "\n",
    "        return output_2\n",
    "\n",
    "model = BERTClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440,
     "referenced_widgets": [
      "73c41d2b554247f4b13342f7a273723c",
      "cd4fe2751a954069b9241814bc5a5dc0",
      "02cc9ebce38749e0bb1f1439fd2a89a8",
      "ea958c94e8c64538b97ccfe2006f1688",
      "a31c3c2f6991447c8b9ef4dda7188f85",
      "3e058b5b66a1424f8ca145735517472e",
      "14ddb37772e944d1a991f9da0eeca27c",
      "77a8f99c330742bb8f6ebe21370bc88e"
     ]
    },
    "id": "lJ5F3GFJ8BLf",
    "outputId": "4591b8e5-7b21-49c7-ed44-1bfed700a7d9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14ce1dea98146cc8de773f14b5416a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.007288726046681404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "total_steps = len(train_dataset) * EPOCHS\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=10,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.tensor(X,dtype=torch.long), y_train_torch)\n",
    "\n",
    "tq = notebook.tqdm(range(EPOCHS))\n",
    "\n",
    "for epoch in tq:\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    tk0 = notebook.tqdm(enumerate(train_loader),total=len(train_loader),leave=False)\n",
    "    \n",
    "    train_loss = 0\n",
    "    for i,(x_batch, y_batch) in tk0:\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # with labels, it outputs loss/\n",
    "            out = model(x_batch.to(device), attention_mask=(x_batch>0).to(device))\n",
    "            loss = custom_loss(out, y_batch.to(device))\n",
    "            train_loss += loss\n",
    "            \n",
    "        # Backprop using loss\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        ret = torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        \n",
    "    print(f\"Training loss:{train_loss/len(train_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "nrAxMRPnrmHN",
    "outputId": "e02b8515-096b-400f-a234-dfb62dc71504"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15625.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Validation loss:0.015533684752881527\n",
      "AUC score : 0.96235\n"
     ]
    }
   ],
   "source": [
    "val_dataset = torch.utils.data.TensorDataset(torch.tensor(X_val,dtype=torch.long), torch.tensor(y_val,dtype=torch.long))\n",
    "valid_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#tk0 = tqdm_notebook(valid_loader)\n",
    "tk0 = notebook.tqdm(enumerate(valid_loader),total=len(valid_loader),leave=False)\n",
    "\n",
    "valid_preds = np.zeros((len(X_val)))\n",
    "val_loss =0\n",
    "for i,(x_batch, y_batch)  in tk0:\n",
    "    with torch.no_grad():       \n",
    "        # Get loss and logits for both classes\n",
    "        y_pred =model(x_batch.to(device), attention_mask=(x_batch>0).to(device))[:,0]\n",
    "        valid_preds[i*batch_size:(i+1)*batch_size] = y_pred.detach().cpu().squeeze().numpy()\n",
    "\n",
    "        # accumulate validatio losses\n",
    "        val_loss += loss\n",
    "print(f\"Validation loss:{val_loss/len(X_val)}\")\n",
    "print('AUC score : {:.5f}'.format(roc_auc_score(y_val.squeeze(), valid_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "BERT_classifying_toxicity_Custom_Loss.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p36)",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02cc9ebce38749e0bb1f1439fd2a89a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e058b5b66a1424f8ca145735517472e",
      "max": 313,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a31c3c2f6991447c8b9ef4dda7188f85",
      "value": 0
     }
    },
    "08df668ae923461e8ae9dfd14a07c11a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14ddb37772e944d1a991f9da0eeca27c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e03aed417bf419997f8085fd2810fd0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3352e65d4cb643c592ea7772ee054dc6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e058b5b66a1424f8ca145735517472e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73c41d2b554247f4b13342f7a273723c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_02cc9ebce38749e0bb1f1439fd2a89a8",
       "IPY_MODEL_ea958c94e8c64538b97ccfe2006f1688"
      ],
      "layout": "IPY_MODEL_cd4fe2751a954069b9241814bc5a5dc0"
     }
    },
    "77a8f99c330742bb8f6ebe21370bc88e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87c3651ba1eb422fb6c08c10eeadcd0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d515018550e641c4b49f35d7f6ae5c80",
      "placeholder": "​",
      "style": "IPY_MODEL_08df668ae923461e8ae9dfd14a07c11a",
      "value": " 15000/15000 [00:16&lt;00:00, 929.22it/s]"
     }
    },
    "a31c3c2f6991447c8b9ef4dda7188f85": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b81cf91d91fc43af86793433688d2109": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3352e65d4cb643c592ea7772ee054dc6",
      "max": 15000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e34be474391a44cc918e4b6aee0f938a",
      "value": 15000
     }
    },
    "cd4fe2751a954069b9241814bc5a5dc0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d515018550e641c4b49f35d7f6ae5c80": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e14b642ce67d4583b118cf9fcb852224": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b81cf91d91fc43af86793433688d2109",
       "IPY_MODEL_87c3651ba1eb422fb6c08c10eeadcd0f"
      ],
      "layout": "IPY_MODEL_1e03aed417bf419997f8085fd2810fd0"
     }
    },
    "e34be474391a44cc918e4b6aee0f938a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ea958c94e8c64538b97ccfe2006f1688": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77a8f99c330742bb8f6ebe21370bc88e",
      "placeholder": "​",
      "style": "IPY_MODEL_14ddb37772e944d1a991f9da0eeca27c",
      "value": " 0/313 [00:00&lt;?, ?it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
