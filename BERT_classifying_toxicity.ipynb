{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rszgAiTgUOEd"
   },
   "source": [
    "Now we will continue on the [Conversation AI](https://conversationai.github.io/) dataset seen in [week 4 homework and lab](https://github.com/MIDS-scaling-up/v2/tree/master/week04). \n",
    "We shall use a version of pytorch BERT for classifying comments found at [https://github.com/huggingface/pytorch-pretrained-BERT](https://github.com/huggingface/pytorch-pretrained-BERT).  \n",
    "\n",
    "The original implementation of BERT is optimised for TPU. Google released some amazing performance improvements on TPU over GPU, for example, see [here](https://medium.com/@ranko.mosic/googles-bert-nlp-5b2bb1236d78) - *BERT relies on massive compute for pre-training ( 4 days on 4 to 16 Cloud TPUs; pre-training on 8 GPUs would take 40â€“70 days).*. In response, Nvidia released [apex](https://devblogs.nvidia.com/apex-pytorch-easy-mixed-precision-training/), which gave mixed precision training. Weights are stored in float32 format, but calculations, like forward and backward propagation happen in float16 - this allows these calculations to be made with a [4X speed up](https://github.com/huggingface/pytorch-pretrained-BERT/issues/149).  \n",
    "\n",
    "We shall apply BERT to the problem for classifiying toxicity, using apex from Nvidia. We shall compare the impact of hardware by running the model on a V100 and P100 and comparing the speed and accuracy in both cases.   \n",
    "\n",
    "This script relies heavily on an existing [Kaggle kernel](https://www.kaggle.com/yuval6967/toxic-bert-plain-vanila) from [yuval r](https://www.kaggle.com/yuval6967). \n",
    "  \n",
    "*Disclaimer: the dataset used contains text that may be considered profane, vulgar, or offensive.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IbxV0iGAUqRc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('data'):\n",
    "  !mkdir data\n",
    "  # Download the training and the test corpus\n",
    "  !wget -nv --show-progress -O data/test.csv.zip https://www.dropbox.com/s/xp6bo8yo1vbv5yg/test.csv.zip?dl=1\n",
    "  !wget -nv --show-progress -O data/train.csv.zip https://www.dropbox.com/s/xei6z41mfrcnxcd/train.csv.zip?dl=1\n",
    "  # Download the pretrained weights for bert base. \n",
    "  !wget -nv --show-progress -O data/uncased_L-12_H-768_A-12.zip \\\n",
    "          https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "\n",
    "  !wget -nv --show-progress  -O data/cased_L-12_H-768_A-12.zip \\\n",
    "          https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip\n",
    "  # unzip weights & conifg and remove the original zip\n",
    "  !unzip -d data/ data/cased_L-12_H-768_A-12.zip && rm data/cased_L-12_H-768_A-12.zip\n",
    "  !unzip -d data/ data/uncased_L-12_H-768_A-12.zip && rm data/uncased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0BWuHJtbUOEe"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm, notebook\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "import pickle\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6iFu29LkUOEg"
   },
   "outputs": [],
   "source": [
    "# Let's activate CUDA for GPU based operations\n",
    "device=torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6wd5Nj6sUOEi"
   },
   "source": [
    "Change the PATH variable to whereever your `week06/hw` directory is located.  \n",
    "**For the final run we would like you to have a train_size of at least 1 Million rows, and a valid size of at least 500K rows. When you first run the script, feel free to work with a reduced train and valid size for speed.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ij0-U4-lUOEj"
   },
   "outputs": [],
   "source": [
    "# In bert we need all inputs to have the same length, we will use the first 220 characters. \n",
    "MAX_SEQUENCE_LENGTH = 220\n",
    "SEED = 1234\n",
    "# We shall run a single epoch (ie. one pass over the data)\n",
    "EPOCHS = 1\n",
    "PATH = '.'#'/root/v2/week06/hw' # /root/v2/week06/hw\"\n",
    "DATA_DIR = os.path.join(PATH, \"data\")\n",
    "WORK_DIR = os.path.join(PATH, \"workingdir\")\n",
    "\n",
    "# Validation and training sizes are here. \n",
    "train_size= 1000000 # 1000000 \n",
    "valid_size= 500000  # 500000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cbtwu2ocUOEm"
   },
   "source": [
    "This should be the files you downloaded earlier when you ran `download.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "EJLTqs_iUOEm",
    "outputId": "56d118b5-fd7a-4018-a106-a9c2bd4091d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.csv.zip',\n",
       " 'test.csv.zip',\n",
       " 'uncased_L-12_H-768_A-12',\n",
       " 'cased_L-12_H-768_A-12']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b8M5zPZEUOEp"
   },
   "source": [
    "We shall install pytorch BERT implementation.   \n",
    "If you would like to experiment with or view any code (purely optional, and not graded :) ), you can copy the files from the repo https://github.com/huggingface/pytorch-pretrained-BERT  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "jedPJmFgVVa1",
    "outputId": "c2ffcc2e-4f12-4d12-aa50-ccaf3ab5e1ff",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (3.2.0)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (4.42.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (2020.7.14)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc2 in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (0.8.1rc2)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from packaging->transformers) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from packaging->transformers) (2.4.6)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: click in /home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sacremoses->transformers) (7.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bNsHYCR5UOEp"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#from transformers import BertModel, BertConfig, BertTokenizer, BertForSequenceClassification\n",
    "from transformers import BertModel, BertConfig,BertTokenizer, AdamW, get_linear_schedule_with_warmup,BertForSequenceClassification\n",
    "import transformers\n",
    "import random\n",
    "#from transformers import AdamW as BertAdam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XHde7udAUOEt"
   },
   "source": [
    "We shall now load the model. When you run this, comment out the `capture` command to understand the archecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s6i06ATuUOEt"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "bert_config = BertConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q_1G4YHcUOEv"
   },
   "source": [
    "Bert needs a special formatting of sentences, so we have a sentence start and end token, as well as separators.   \n",
    "Thanks to this [script](https://www.kaggle.com/httpwwwfszyc/bert-in-keras-taming) for a fast convertor of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DrBmqp7BUOEv"
   },
   "outputs": [],
   "source": [
    "def convert_lines(example, max_seq_length,tokenizer):\n",
    "    max_seq_length -=2\n",
    "    all_tokens = []\n",
    "    longer = 0\n",
    "    for text in notebook.tqdm(example):\n",
    "        tokens_a = tokenizer.tokenize(text)\n",
    "        if len(tokens_a)>max_seq_length:\n",
    "            tokens_a = tokens_a[:max_seq_length]\n",
    "            longer += 1\n",
    "        one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"]+tokens_a+[\"[SEP]\"])+[0] * (max_seq_length - len(tokens_a))\n",
    "        all_tokens.append(one_token)\n",
    "    print(longer)\n",
    "    return np.array(all_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_qEXfL7UOEx"
   },
   "source": [
    "Now we load the BERT tokenizer and convert the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185,
     "referenced_widgets": [
      "26ad8c0e3c7745c69780bf9f476bf758",
      "1f3c66877b4f4ca1a9a0ffe059246658",
      "dde28ca6a8104662a4bcecd5ed2ebb52",
      "59458339c6d94dfeb7cdb6792213aaa9",
      "c6c476e2980d463483efeb8ed6424765",
      "4540ef932e454d54974477ae9c19a34c",
      "6637f52ea97e482f9c1006421edfa0f6",
      "47796286f03a43e9a8751c4aa4fa001e"
     ]
    },
    "colab_type": "code",
    "id": "R9DizVjNUOEy",
    "outputId": "1ba48fd3-c646-4182-ecf9-fec562b9b261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 1500000 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66765e36b27347ff8c6c6f1439906f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1500000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "33722\n",
      "CPU times: user 28min 17s, sys: 6.86 s, total: 28min 24s\n",
      "Wall time: 28min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, cache_dir=None,do_lower_case=True)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_all = pd.read_csv(os.path.join(DATA_DIR, \"train.csv.zip\")).sample(train_size+valid_size,random_state=SEED)\n",
    "print('loaded %d records' % len(train_all))\n",
    "\n",
    "# Make sure all comment_text values are strings\n",
    "train_all['comment_text'] = train_all['comment_text'].astype(str) \n",
    "\n",
    "sequences = convert_lines(train_all[\"comment_text\"].fillna(\"DUMMY_VALUE\"),MAX_SEQUENCE_LENGTH,tokenizer)\n",
    "train_all=train_all.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n1CWpDnZUOE0"
   },
   "source": [
    "Let us look at how the tokenising works in BERT, see below how it recongizes misspellings - words the model never saw. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "_5pJu1yeUOE0",
    "outputId": "791b45f4-31cc-4992-a024-5b85f0c202d9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>458232</th>\n",
       "      <td>It's difficult for many old people to keep up ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272766</th>\n",
       "      <td>She recognized that her tiny-handed husband is...</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339129</th>\n",
       "      <td>HPHY76,\\nGood for you for thinking out loud, w...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773565</th>\n",
       "      <td>And I bet that in the day you expected your Je...</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476233</th>\n",
       "      <td>Kennedy will add a much needed and scientifica...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text    target\n",
       "458232  It's difficult for many old people to keep up ...  0.000000\n",
       "272766  She recognized that her tiny-handed husband is...  0.166667\n",
       "339129  HPHY76,\\nGood for you for thinking out loud, w...  0.000000\n",
       "773565  And I bet that in the day you expected your Je...  0.500000\n",
       "476233  Kennedy will add a much needed and scientifica...  0.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all[[\"comment_text\", 'target']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6LEwoL3wUOE2"
   },
   "source": [
    "Lets tokenize some text (I intentionally mispelled some words to check berts subword information handling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "xSWZdjQKUOE2",
    "outputId": "dc4a5d5a-6524-4646-8e96-d499b6965b8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi , i am learning new things in w ##25 ##1 about deep learning the cloud and te ##h edge .'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Hi, I am learning new things in w251 about deep learning the cloud and teh edge.'\n",
    "tokens = tokenizer.tokenize(text)\n",
    "' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "coegyu-6UOE5"
   },
   "source": [
    "Added start and end token and convert to ids. This is how it is fed into BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "AfV1jtuoUOE5",
    "outputId": "f088d6d4-e302-4ee0-8f9c-06e88984d328"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'101 7632 1010 1045 2572 4083 2047 2477 1999 1059 17788 2487 2055 2784 4083 1996 6112 1998 8915 2232 3341 1012 102'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "' '.join(map(str, input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KyH14gQDUOE7"
   },
   "source": [
    "When BERT converts this sentence to a torch tensor below is shape of the stored tensors.  \n",
    "We have 12 input tensors, while the sentence tokens has length 23; where are can you see the 23 tokens in the tensors ?... **Feel free to post in slack or discuss in class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "sCSuhcB0UOE7",
    "outputId": "3f4ee749-de04-41a5-f08c-54486953c6e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence tokens ['[CLS]', 'hi', ',', 'i', 'am', 'learning', 'new', 'things', 'in', 'w', '##25', '##1', 'about', 'deep', 'learning', 'the', 'cloud', 'and', 'te', '##h', 'edge', '.', '[SEP]']\n",
      "Number of tokens 23\n",
      "Tensor shapes : [(2,)]\n",
      "Number of torch tensors : 1\n"
     ]
    }
   ],
   "source": [
    "# put input on gpu and make prediction\n",
    "bert = BertForSequenceClassification.from_pretrained('bert-base-uncased').cuda()\n",
    "# bert = BertModel.from_pretrained(WORK_DIR).cuda()\n",
    "bert_output = bert(torch.tensor([input_ids]).cuda())\n",
    "\n",
    "print('Sentence tokens {}'.format(tokens))\n",
    "print('Number of tokens {}'.format(len(tokens)))\n",
    "print('Tensor shapes : {}'.format([b.cpu().detach().numpy().shape for b in bert_output[0]]))\n",
    "print('Number of torch tensors : {}'.format(len(bert_output[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4qG6hOEdUOE9"
   },
   "source": [
    "As it is a binary problem, we change our target to [0,1], instead of float.   \n",
    "We also split the dataset into a training and validation set, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NJTdc6CsUOE9"
   },
   "outputs": [],
   "source": [
    "train_all['target']=(train_all['target']>=0.5).astype(float)\n",
    "# Training data - sentences\n",
    "X = sequences[:train_size] \n",
    "# Target - the toxicity. \n",
    "y = train_all[['target']].values[:train_size]\n",
    "X_val = sequences[train_size:]                \n",
    "y_val = train_all[['target']].values[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "41iPfLWOUOE_",
    "outputId": "c57e9398-577f-4a42-d913-1be4cbeb87e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  2009,  2038, ...,     0,     0,     0],\n",
       "       [  101,  2111,  2040, ...,     0,     0,     0],\n",
       "       [  101, 10413, 21442, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  3239, 28402, ...,     0,     0,     0],\n",
       "       [  101,  2004,  2467, ...,     0,     0,     0],\n",
       "       [  101,  3530,  1010, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3vq8oRglUOFE"
   },
   "source": [
    "**From here on in we would like you to run BERT.**   \n",
    "**Please do rely on the script available -  [Kaggle kernel](https://www.kaggle.com/yuval6967/toxic-bert-plain-vanila) from [yuval r](https://www.kaggle.com/yuval6967) - for at least the first few steps up to training and prediction.**  \n",
    "    \n",
    "**Note, instead of using the apex in yuval's code, we would like you to use the new native [pytorch apex version](https://pytorch.org/docs/stable/amp.html).** \n",
    "**You can see some examples of native [apex](https://pytorch.org/docs/stable/notes/amp_examples.html#typical-mixed-precision-training) here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w6e_9U0HUOFE"
   },
   "source": [
    "\n",
    "**1)**   \n",
    "**Load the training set to a training dataset. For this you need to load the X sequences and y objects to torch tensors**   \n",
    "**You can use `torch.utils.data.TensorDataset` to input these into a train_dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OT97eHrTUOFF"
   },
   "outputs": [],
   "source": [
    "# Training data creations\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.tensor(X,dtype=torch.long), torch.tensor(y,dtype=torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M3b72Pr9UOFG"
   },
   "source": [
    "**2)**  \n",
    "**Set your learning rate and batch size; and optionally random seeds if you want reproducable results**   \n",
    "**Load your pretrained BERT using `BertForSequenceClassification`**   \n",
    "**Initialise the gradients and place the model on cuda, set up your optimiser and decay parameters**\n",
    "**note, we will not use apex like yuval. So no `amp.initialise` needed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xvs2jTHuUOFH"
   },
   "outputs": [],
   "source": [
    "output_model_file = \"bert_pytorch.bin\"\n",
    "\n",
    "batch_size = 32\n",
    "accumulation_steps=2\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "train = train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fifCQvMcUOFI"
   },
   "source": [
    "**3)**  \n",
    "**Start training your model by iterating through batches in a single epoch of the data**    \n",
    "**I copied the new amp process shown [here](https://github.com/aws/deep-learning-containers/blob/b9ccd5928fe2ecd8aafc4c1660b39fe265ed879f/test/dlc_tests/container_tests/bin/pytorch_tests/testPyTorchAMP#L31-L40) and it worked out.**   \n",
    "A few tips on the changes needed,   \n",
    "1) You will need to use `torch.cuda.amp.autocast()` and `torch.cuda.amp.GradScaler()` like seen in the reference code. \n",
    "2) From yuval's code, the prediction and loss calculation must be executed with autocast (see new amp process code).      \n",
    "3) Loss scaling, the omptimiser step and update can be taken from the new amp code, but please do the optimiser step and update with accumulation from yuval's code.     \n",
    "4) For some reason, yuval's code, in the `y_pred` line, returns a tuple when run with autocast. Just index into the first element to get the prediction.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NeAeAtE2z7GZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134,
     "referenced_widgets": [
      "977f92ab4b7047ce8583449d5b6a0a7f",
      "aab33db76fac40058e6628395765c44b",
      "90b1ea2e39bb419b80ab8a512ba264fd",
      "9414a14c56954822aa90b061b590a047",
      "3f02e1cc32c646c0ac5111e9b7702ed5",
      "f59d39c62c36454cb0d04e615f6b202c",
      "c2b619472c2a4ace9dc0bdf1623c7bb8",
      "bfa1b35104be481ca9b6fbca798a53dd",
      "0d038f9c292a4111b668c92573a38867",
      "8a8fe70880fd4803bc304fe4704f44d0",
      "2a9e684e9aab4a619b0510e125b6384c",
      "8e4d7a4d2dde41c18a03924164713be0",
      "76457d5a223a415a9531432700a8ef2d",
      "e8bcebcd4f8c4c66b003108660103217",
      "1f5bd78b0dff4eb58f7739d689c8d409",
      "6cee1f98370048489a17bd32d654f1c0"
     ]
    },
    "colab_type": "code",
    "id": "wmeSOfn-UOFJ",
    "outputId": "32ca2b2a-a646-450f-b1b6-bdafb55fa12d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1b3f195cad4755ab278967a56fd7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.003979182336479425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = bert.train()\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "\n",
    "total_steps = len(train_dataset) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "tq = notebook.tqdm(range(EPOCHS))\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "for epoch in tq:\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    tk0 = notebook.tqdm(enumerate(train_loader),total=len(train_loader),leave=False)\n",
    "    \n",
    "    train_loss = 0\n",
    "    for i,(x_batch, y_batch) in tk0:\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # with labels, it outputs loss\n",
    "            loss = model(x_batch.to(device), attention_mask=(x_batch>0).to(device),labels=y_batch.to(device))[0]\n",
    "            train_loss += loss\n",
    "            \n",
    "        # Backprop using loss\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        ret = torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        \n",
    "    print(f\"Training loss:{train_loss/len(train_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LyUpiJErUOFK"
   },
   "source": [
    "**4)**  \n",
    "**Store your trained model to disk, you will need it if you choose section 8C.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SHHugvrTUOFK"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), output_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D5V--WfVUOFM"
   },
   "source": [
    "**5)**   \n",
    "**Now make a prediction for your validation set.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134,
     "referenced_widgets": [
      "a4d16ac309234db389134ac47ffad207",
      "e6a79cc6126f41dc873bd832b5a67d15",
      "27988d82ee154f4baa0276d61edb89f9",
      "a6b03d6bda93424989c2b74f11a4bd67",
      "bd4851667cf64adfbe29cb9ca0a999ad",
      "dc6f210adf6249b18214758bcaa2b58c",
      "ab08b016a13c4f5f80c2fb747c6440e2",
      "745ab5890d4b4efa9a8b2e4fe81d3f96"
     ]
    },
    "colab_type": "code",
    "id": "hgm-k8CAUOFM",
    "outputId": "fc1b26b6-16d6-484d-b7ee-3ba9526e0899"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27709fc7f2a042c1a48f64fd99307592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15625.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loss:0.0038657193072140217\n"
     ]
    }
   ],
   "source": [
    "val_dataset = torch.utils.data.TensorDataset(torch.tensor(X_val,dtype=torch.long), torch.tensor(y_val,dtype=torch.long))\n",
    "valid_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "tk0 = notebook.tqdm(valid_loader)\n",
    "\n",
    "valid_preds = np.zeros((len(X_val)))\n",
    "val_loss =0\n",
    "for i,(x_batch, y_batch)  in enumerate(tk0):\n",
    "    with torch.no_grad():       \n",
    "        # Get loss and logits for both classes\n",
    "        loss,y_pred =model(x_batch.to(device), attention_mask=(x_batch>0).to(device),labels = y_batch.to(device))\n",
    "        # Pass through SoftMax to get probablity\n",
    "        y_pred_prob = nn.LogSoftmax(dim =1)(y_pred)[:, 1]\n",
    "        \n",
    "        valid_preds[i*batch_size:(i+1)*batch_size] = y_pred_prob.detach().cpu().squeeze().numpy()\n",
    "\n",
    "        # accumulate validatio losses\n",
    "        val_loss += loss\n",
    "print(f\"Validation loss:{val_loss/len(X_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LqU8dATNUOFO"
   },
   "source": [
    "**6)**  \n",
    "**In the yuval's kernel he get a metric based on the metric for the jigsaw competition - it is quite complicated. Instead, we would like you to measure the `AUC`, similar to how you did in homework 04. You can compare the results to HW04**  \n",
    "*A tip, if your score is lower than homework 04 something is wrong....*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hkW9d2QTUOFO",
    "outputId": "e338f1a3-b453-48da-dc23-8d169a08f53b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score : 0.96333\n"
     ]
    }
   ],
   "source": [
    "print('AUC score : {:.5f}'.format(roc_auc_score(y_val.squeeze(), valid_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9qyXWScvUOFQ"
   },
   "source": [
    "**7)**  \n",
    "**Can you show/print the validation sentences predicted with the highest and lowest toxicity ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "o5pfZW70UOFQ",
    "outputId": "a3022ba5-c3b2-4c9f-a674-e210539c955c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic score:0.9897601231101616\n",
      "Tokens:\n",
      "[CLS] so tr ##udeau just told all of canada that canadian laws only apply to non muslims ! muslims are free to ignore canadian law ! once again tr ##udeau proves he is just a useful idiot for islam ! [SEP]                                                                                                                                                                                   \n",
      "Original comment:\n",
      "So trudeau just told all of Canada that Canadian laws only apply to non muslims!\n",
      "\n",
      "muslims are free to ignore Canadian law!\n",
      "\n",
      "Once again trudeau proves he is just a useful idiot for islam!\n",
      "\n",
      "\n",
      "Toxic score: 0.0003561493920646834\n",
      "Tokens:\n",
      "[CLS] this is why she will likely win , she appeals to a broader base . [SEP]                                                                                                                                                                                                           \n",
      "Original comment:\n",
      "This is why she will likely win, she appeals to a broader base.\n"
     ]
    }
   ],
   "source": [
    "highest_toxic = np.argmax(valid_preds)\n",
    "print('Toxic score:' + str(np.exp(valid_preds[highest_toxic])))\n",
    "print('Tokens:\\n' + ' '.join(tokenizer.convert_ids_to_tokens(X_val[highest_toxic])).replace('[PAD]',''))\n",
    "print('Original comment:\\n' + train_all.iloc[train_size + highest_toxic][\"comment_text\"])\n",
    "print('\\n')\n",
    "lowest_toxic = np.argmin(valid_preds)\n",
    "print('Toxic score:', np.exp(valid_preds[lowest_toxic]))\n",
    "print('Tokens:\\n' + ' '.join(tokenizer.convert_ids_to_tokens(X_val[lowest_toxic])).replace('[PAD]',''))\n",
    "print('Original comment:\\n' + train_all.iloc[train_size + lowest_toxic][\"comment_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S2wD6mdfUOFS"
   },
   "source": [
    "**8)**  \n",
    "**Pick only one of the below items and complete it. The last two will take a good amount of time (and partial success on them is fine), so proceed with caution on your choice of items :)** \n",
    "  \n",
    "  \n",
    "**A. Can you train on two epochs ?**\n",
    "\n",
    "**B. Can you change the learning rate and improve validation score ?**\n",
    "   \n",
    "**C. Make a prediction on the test data set with your downloaded model and submit to Kaggle to see where you score on public LB - check out [Abhishek's](https://www.kaggle.com/abhishek) script - https://www.kaggle.com/abhishek/pytorch-bert-inference . Note, you will need to fork Abhisheks kernel, swap out the weights to your downloaded weights and commit the kernel. When finalised and you get the output, there is a button to submit to the competition**  \n",
    "  \n",
    "**D. Get BERT running on the tx2 for a sample of the data.** \n",
    "  \n",
    "**E. Finally, and very challenging -- the `BertAdam` optimiser proved to be suboptimal for this task. There is a better optimiser for this dataset in this script [here](https://www.kaggle.com/cristinasierra/pretext-lstm-tuning-v3). Check out the `custom_loss` function. Can you implement it ? It means getting under the hood of the `BertForSequenceClassification` at the source repo and implementing a modified version locally .  `https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/pytorch_pretrained_bert/modeling.py`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bfQVU9SXUOFU"
   },
   "source": [
    "### **Remember to terminate your instance at the end.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "BERT_classifying_toxicity.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "azureml_py36_pytorch",
   "language": "python",
   "name": "conda-env-azureml_py36_pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d038f9c292a4111b668c92573a38867": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2a9e684e9aab4a619b0510e125b6384c",
       "IPY_MODEL_8e4d7a4d2dde41c18a03924164713be0"
      ],
      "layout": "IPY_MODEL_8a8fe70880fd4803bc304fe4704f44d0"
     }
    },
    "1f3c66877b4f4ca1a9a0ffe059246658": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f5bd78b0dff4eb58f7739d689c8d409": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26ad8c0e3c7745c69780bf9f476bf758": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dde28ca6a8104662a4bcecd5ed2ebb52",
       "IPY_MODEL_59458339c6d94dfeb7cdb6792213aaa9"
      ],
      "layout": "IPY_MODEL_1f3c66877b4f4ca1a9a0ffe059246658"
     }
    },
    "27988d82ee154f4baa0276d61edb89f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc6f210adf6249b18214758bcaa2b58c",
      "max": 157,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bd4851667cf64adfbe29cb9ca0a999ad",
      "value": 157
     }
    },
    "2a9e684e9aab4a619b0510e125b6384c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8bcebcd4f8c4c66b003108660103217",
      "max": 313,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_76457d5a223a415a9531432700a8ef2d",
      "value": 313
     }
    },
    "3f02e1cc32c646c0ac5111e9b7702ed5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4540ef932e454d54974477ae9c19a34c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47796286f03a43e9a8751c4aa4fa001e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59458339c6d94dfeb7cdb6792213aaa9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47796286f03a43e9a8751c4aa4fa001e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6637f52ea97e482f9c1006421edfa0f6",
      "value": " 15000/15000 [00:11&lt;00:00, 1314.79it/s]"
     }
    },
    "6637f52ea97e482f9c1006421edfa0f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6cee1f98370048489a17bd32d654f1c0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "745ab5890d4b4efa9a8b2e4fe81d3f96": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76457d5a223a415a9531432700a8ef2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8a8fe70880fd4803bc304fe4704f44d0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e4d7a4d2dde41c18a03924164713be0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6cee1f98370048489a17bd32d654f1c0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_1f5bd78b0dff4eb58f7739d689c8d409",
      "value": " 313/313 [03:42&lt;00:00,  1.64it/s]"
     }
    },
    "90b1ea2e39bb419b80ab8a512ba264fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f59d39c62c36454cb0d04e615f6b202c",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3f02e1cc32c646c0ac5111e9b7702ed5",
      "value": 1
     }
    },
    "9414a14c56954822aa90b061b590a047": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bfa1b35104be481ca9b6fbca798a53dd",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c2b619472c2a4ace9dc0bdf1623c7bb8",
      "value": " 1/1 [03:42&lt;00:00, 222.06s/it]"
     }
    },
    "977f92ab4b7047ce8583449d5b6a0a7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_90b1ea2e39bb419b80ab8a512ba264fd",
       "IPY_MODEL_9414a14c56954822aa90b061b590a047"
      ],
      "layout": "IPY_MODEL_aab33db76fac40058e6628395765c44b"
     }
    },
    "a4d16ac309234db389134ac47ffad207": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_27988d82ee154f4baa0276d61edb89f9",
       "IPY_MODEL_a6b03d6bda93424989c2b74f11a4bd67"
      ],
      "layout": "IPY_MODEL_e6a79cc6126f41dc873bd832b5a67d15"
     }
    },
    "a6b03d6bda93424989c2b74f11a4bd67": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_745ab5890d4b4efa9a8b2e4fe81d3f96",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_ab08b016a13c4f5f80c2fb747c6440e2",
      "value": " 157/157 [00:34&lt;00:00,  4.61it/s]"
     }
    },
    "aab33db76fac40058e6628395765c44b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab08b016a13c4f5f80c2fb747c6440e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bd4851667cf64adfbe29cb9ca0a999ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "bfa1b35104be481ca9b6fbca798a53dd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2b619472c2a4ace9dc0bdf1623c7bb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c6c476e2980d463483efeb8ed6424765": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "dc6f210adf6249b18214758bcaa2b58c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dde28ca6a8104662a4bcecd5ed2ebb52": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4540ef932e454d54974477ae9c19a34c",
      "max": 15000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c6c476e2980d463483efeb8ed6424765",
      "value": 15000
     }
    },
    "e6a79cc6126f41dc873bd832b5a67d15": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8bcebcd4f8c4c66b003108660103217": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f59d39c62c36454cb0d04e615f6b202c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
